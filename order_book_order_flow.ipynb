{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhph5R52cFrXNtEMtKWp2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malik-Raheel/Trading-Strategies/blob/main/order_book_order_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from market maker's edge this is drived from chapter 6 7"
      ],
      "metadata": {
        "id": "JL6nGvILjjOg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRszgFEDjdSy",
        "outputId": "d7c2d0cf-4bff-4a90-f93f-639c5febb1b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ccxt\n",
            "  Downloading ccxt-4.4.63-py2.py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m668.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting pandas-ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.11/dist-packages (from ccxt) (75.1.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.11/dist-packages (from ccxt) (2025.1.31)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.11/dist-packages (from ccxt) (2.32.3)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ccxt) (43.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from ccxt) (4.12.2)\n",
            "Collecting aiohttp<=3.10.11 (from ccxt)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiodns>=1.1.1 (from ccxt)\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ccxt) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt)\n",
            "  Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<=3.10.11->ccxt) (6.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.6.1->ccxt) (1.17.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->ccxt) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->ccxt) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->ccxt) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl>=1.7.2->ccxt) (0.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading ccxt-4.4.63-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
            "Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.6/288.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pandas-ta\n",
            "  Building wheel for pandas-ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218909 sha256=93df8977fcce127185398ec4ca12aecc9e4f3c775ac544e290e04e055be4e5d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/33/8b/50b245c5c65433cd8f5cb24ac15d97e5a3db2d41a8b6ae957d\n",
            "Successfully built pandas-ta\n",
            "Installing collected packages: pycares, aiohttp, pandas-ta, aiodns, ccxt\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.12\n",
            "    Uninstalling aiohttp-3.11.12:\n",
            "      Successfully uninstalled aiohttp-3.11.12\n",
            "Successfully installed aiodns-3.2.0 aiohttp-3.10.11 ccxt-4.4.63 pandas-ta-0.3.14b0 pycares-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ccxt pandas numpy scikit-learn tensorflow pandas-ta matplotlib plotly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Initialize KuCoin API\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Function to fetch Level 2 order book data\n",
        "def fetch_order_book(symbol):\n",
        "    order_book = exchange.fetch_order_book(symbol, limit=20)  # Top 10 bid/ask levels\n",
        "    bids = order_book['bids']\n",
        "    asks = order_book['asks']\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    bids_df = pd.DataFrame(bids, columns=['Price', 'Size'])\n",
        "    asks_df = pd.DataFrame(asks, columns=['Price', 'Size'])\n",
        "\n",
        "    return bids_df, asks_df\n",
        "\n",
        "# Fetch data for AVAX/USDT and JUP/USDT\n",
        "bids_avax, asks_avax = fetch_order_book('AVAX/USDT')\n",
        "bids_jup, asks_jup = fetch_order_book('JUP/USDT')\n",
        "\n",
        "# Display Order Book Data\n",
        "print(\"AVAX/USDT - Bids:\")\n",
        "print(bids_avax)\n",
        "print(\"AVAX/USDT - Asks:\")\n",
        "print(asks_avax)\n",
        "\n",
        "# Feature Engineering\n",
        "def preprocess_order_book(bids, asks):\n",
        "    best_bid = bids.iloc[0]['Price']\n",
        "    best_ask = asks.iloc[0]['Price']\n",
        "\n",
        "    spread = best_ask - best_bid  # Spread Calculation\n",
        "\n",
        "    total_bid_volume = bids['Size'].sum()\n",
        "    total_ask_volume = asks['Size'].sum()\n",
        "\n",
        "    bid_ask_imbalance = (total_bid_volume - total_ask_volume) / (total_bid_volume + total_ask_volume)\n",
        "\n",
        "    # VWAP Calculation\n",
        "    vwap_bids = (bids['Price'] * bids['Size']).sum() / total_bid_volume\n",
        "    vwap_asks = (asks['Price'] * asks['Size']).sum() / total_ask_volume\n",
        "\n",
        "    return [best_bid, best_ask, spread, bid_ask_imbalance, vwap_bids, vwap_asks]\n",
        "\n",
        "# Prepare Data for AVAX/USDT\n",
        "avax_features = preprocess_order_book(bids_avax, asks_avax)\n",
        "print(\"AVAX Order Flow Features:\", avax_features)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create Dataset\n",
        "data = []  # Collecting data over time\n",
        "\n",
        "# Fetch data every 5 seconds for 10 minutes\n",
        "for _ in range(120):  # 120 samples (10 minutes)\n",
        "    bids_avax, asks_avax = fetch_order_book('AVAX/USDT')\n",
        "    avax_features = preprocess_order_book(bids_avax, asks_avax)\n",
        "    data.append(avax_features)\n",
        "    time.sleep(5)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data, columns=['Best_Bid', 'Best_Ask', 'Spread', 'Imbalance', 'VWAP_Bids', 'VWAP_Asks'])\n",
        "\n",
        "# Normalize Data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "# Prepare LSTM Training Data\n",
        "X, y = [], []\n",
        "seq_length = 10  # Use last 10 steps to predict next\n",
        "\n",
        "for i in range(len(scaled_data) - seq_length):\n",
        "    X.append(scaled_data[i:i+seq_length])\n",
        "    y.append(scaled_data[i+seq_length, 3])  # Predict Imbalance\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(seq_length, X.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, y, epochs=20, batch_size=8, verbose=1)\n",
        "\n",
        "print(\"LSTM Model Training Complete!\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fetch New Live Data for Prediction\n",
        "bids_avax, asks_avax = fetch_order_book('AVAX/USDT')\n",
        "new_features = preprocess_order_book(bids_avax, asks_avax)\n",
        "scaled_features = scaler.transform([new_features])\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_new = np.array([scaled_features])\n",
        "prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "# Define Trading Signal\n",
        "if prediction > 0.2:\n",
        "    signal = \"BUY Signal ðŸš€\"\n",
        "elif prediction < -0.2:\n",
        "    signal = \"SELL Signal ðŸ”»\"\n",
        "else:\n",
        "    signal = \"NO TRADE âŒ\"\n",
        "\n",
        "print(f\"Predicted Order Flow Imbalance: {prediction:.2f}\")\n",
        "print(f\"Trading Signal: {signal}\")\n",
        "\n",
        "# Visualize Order Flow Imbalance Over Time\n",
        "plt.plot(y, label='Actual Imbalance')\n",
        "plt.axhline(y=0.2, color='g', linestyle='--', label='Buy Threshold')\n",
        "plt.axhline(y=-0.2, color='r', linestyle='--', label='Sell Threshold')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MAHbuvJ_vd4J",
        "outputId": "012aa6d2-c405-4b29-a65b-57f73f4c9be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AVAX/USDT - Bids:\n",
            "     Price      Size\n",
            "0   24.143   23.8390\n",
            "1   24.140    4.1606\n",
            "2   24.139   25.3173\n",
            "3   24.138    1.3763\n",
            "4   24.137   22.3317\n",
            "5   24.136   24.9907\n",
            "6   24.134   17.5500\n",
            "7   24.133   20.4018\n",
            "8   24.132    9.9459\n",
            "9   24.131   23.4172\n",
            "10  24.130   11.7395\n",
            "11  24.129   45.2568\n",
            "12  24.128   24.2866\n",
            "13  24.123   17.5500\n",
            "14  24.120   57.3510\n",
            "15  24.119  132.6700\n",
            "16  24.118   26.2080\n",
            "17  24.117   11.4534\n",
            "18  24.116   38.1779\n",
            "19  24.115   20.7004\n",
            "AVAX/USDT - Asks:\n",
            "     Price      Size\n",
            "0   24.144    1.8564\n",
            "1   24.147    1.3763\n",
            "2   24.148    0.4356\n",
            "3   24.149   23.1484\n",
            "4   24.151   24.9705\n",
            "5   24.152   29.5358\n",
            "6   24.153   26.2070\n",
            "7   24.154   36.4166\n",
            "8   24.155   49.3838\n",
            "9   24.156    9.9360\n",
            "10  24.157   21.3323\n",
            "11  24.158   17.5500\n",
            "12  24.159   22.1924\n",
            "13  24.160   22.2638\n",
            "14  24.163   14.4637\n",
            "15  24.164   48.2123\n",
            "16  24.165   17.5500\n",
            "17  24.167   65.6159\n",
            "18  24.168  162.9525\n",
            "19  24.169   54.5874\n",
            "AVAX Order Flow Features: [24.143, 24.144, 0.0009999999999976694, -0.07550408253157012, 24.12554952578563, 24.161538235320812]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0998\n",
            "Epoch 2/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0467\n",
            "Epoch 3/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0444\n",
            "Epoch 4/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0381\n",
            "Epoch 5/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0388\n",
            "Epoch 6/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0358\n",
            "Epoch 7/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0373\n",
            "Epoch 8/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0321\n",
            "Epoch 9/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0333\n",
            "Epoch 10/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0383\n",
            "Epoch 11/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0322\n",
            "Epoch 12/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0400\n",
            "Epoch 13/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0393\n",
            "Epoch 14/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0326\n",
            "Epoch 15/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0303\n",
            "Epoch 16/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0332\n",
            "Epoch 17/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0329\n",
            "Epoch 18/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0315\n",
            "Epoch 19/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0321\n",
            "Epoch 20/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0301\n",
            "LSTM Model Training Complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "Predicted Order Flow Imbalance: 0.08\n",
            "Trading Signal: NO TRADE âŒ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now it incorporates filled order data to check aggressive buying or selling"
      ],
      "metadata": {
        "id": "PNBeaNv20BFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "# Fetch Level 2 Order Book (Fixing Limit Issue)\n",
        "def fetch_order_book(symbol, depth=20):  # KuCoin only allows 20 or 100\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    if depth not in [20, 100]:\n",
        "        depth = 20  # Defaulting to 20 to avoid errors\n",
        "    order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "    bids = order_book['bids'][:depth]  # Top bids\n",
        "    asks = order_book['asks'][:depth]  # Top asks\n",
        "    return bids, asks\n",
        "\n",
        "# Fetch Order Book Data (Now Working)\n",
        "bids, asks = fetch_order_book('AVAX/USDT', depth=20)  # Fixed\n",
        "\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=100):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "    df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe='4h'):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    trade_df = trade_df.set_index('timestamp')\n",
        "    resampled = trade_df.resample(timeframe).agg({\n",
        "        'amount': 'sum', 'price': 'mean',\n",
        "        'side': lambda x: (x == 'buy').sum()\n",
        "    })\n",
        "\n",
        "    resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "    resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "    resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "    resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "    resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "    resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "    return resampled\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    bid_prices = np.array([bid[0] for bid in bids])\n",
        "    bid_sizes = np.array([bid[1] for bid in bids])\n",
        "    ask_prices = np.array([ask[0] for ask in asks])\n",
        "    ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "    spread = ask_prices[0] - bid_prices[0]\n",
        "    vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "    imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "\n",
        "    return [spread, vwap, imbalance]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 6)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fetch Both Order Book & Trade Data\n",
        "bids, asks = fetch_order_book('AVAX/USDT')\n",
        "trade_data = fetch_trade_data('AVAX/USDT')\n",
        "\n",
        "# Get Aggressive Order Flow Analysis\n",
        "aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')\n",
        "aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')\n",
        "\n",
        "# Extract Latest Values\n",
        "last_4h_delta = aggressive_orders_4h['delta'].iloc[-1]\n",
        "last_4h_cvd = aggressive_orders_4h['cumulative_delta'].iloc[-1]\n",
        "\n",
        "last_15m_delta = aggressive_orders_15m['delta'].iloc[-1]\n",
        "last_15m_cvd = aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "\n",
        "# Combine Order Book & Aggressive Order Flow Data\n",
        "new_features = preprocess_order_book(bids, asks) + [last_4h_delta, last_4h_cvd, last_15m_delta, last_15m_cvd]\n",
        "scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "# Make LSTM Prediction\n",
        "# Ensure X_new only has 6 features (adjust if needed)\n",
        "X_new = np.array([scaled_features[:6]])  # Keep only first 6 features\n",
        "\n",
        "# Keep only the first 6 features\n",
        "X_new = X_new[:6]\n",
        "\n",
        "# Reshape to match LSTM input (1 sample, 1 time step, 6 features)\n",
        "X_new = X_new.reshape(1, 1, 6)\n",
        "\n",
        "# Make Prediction\n",
        "prediction = model.predict(X_new)[0][0]\n",
        "print(\"Prediction:\", prediction)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate Trading Signal\n",
        "if prediction > 0.2:\n",
        "    signal = \"BUY Signal ðŸš€\"\n",
        "elif prediction < -0.2:\n",
        "    signal = \"SELL Signal ðŸ”»\"\n",
        "else:\n",
        "    signal = \"NO TRADE âŒ\"\n",
        "\n",
        "# Output Required Data\n",
        "print(f\"Trading Signal: {signal}\")\n",
        "print(f\"Aggressive Buying/Selling (4H): {last_4h_delta}\")\n",
        "print(f\"Aggressive Buying/Selling (15M): {last_15m_delta}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "7PCjz9gM0F3C",
        "outputId": "05fa41ee-4392-4fb3-f9df-a8efe219da68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 7 into shape (1,1,6)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-421bd2adfacb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# Reshape to match LSTM input (1 sample, 1 time step, 6 features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Make Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7 into shape (1,1,6)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):  # KuCoin only allows 20 or 100\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    if depth not in [20, 100]:\n",
        "        depth = 20  # Defaulting to 20 to avoid errors\n",
        "    order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "    bids = order_book['bids'][:depth]  # Top bids\n",
        "    asks = order_book['asks'][:depth]  # Top asks\n",
        "    return bids, asks\n",
        "\n",
        "# Fetch Order Book Data\n",
        "bids, asks = fetch_order_book('AVAX/USDT', depth=20)  # Fixed\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=100):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "    df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe='4h'):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    trade_df = trade_df.set_index('timestamp')\n",
        "    resampled = trade_df.resample(timeframe).agg({\n",
        "        'amount': 'sum', 'price': 'mean',\n",
        "        'side': lambda x: (x == 'buy').sum()\n",
        "    })\n",
        "\n",
        "    resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "    resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "    resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "    resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "    resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "    resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "    return resampled\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    bid_prices = np.array([bid[0] for bid in bids])\n",
        "    bid_sizes = np.array([bid[1] for bid in bids])\n",
        "    ask_prices = np.array([ask[0] for ask in asks])\n",
        "    ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "    spread = ask_prices[0] - bid_prices[0]\n",
        "    vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "    imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "\n",
        "    return [spread, vwap, imbalance]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 6)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fetch Both Order Book & Trade Data\n",
        "bids, asks = fetch_order_book('AVAX/USDT')\n",
        "trade_data = fetch_trade_data('AVAX/USDT')\n",
        "\n",
        "# Get Aggressive Order Flow Analysis\n",
        "aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')\n",
        "aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')\n",
        "\n",
        "# Extract Latest Values\n",
        "last_4h_delta = aggressive_orders_4h['delta'].iloc[-1]\n",
        "last_4h_cvd = aggressive_orders_4h['cumulative_delta'].iloc[-1]\n",
        "\n",
        "last_15m_delta = aggressive_orders_15m['delta'].iloc[-1]\n",
        "last_15m_cvd = aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "\n",
        "# Combine Order Book & Aggressive Order Flow Data\n",
        "new_features = preprocess_order_book(bids, asks) + [last_4h_delta, last_4h_cvd, last_15m_delta, last_15m_cvd]\n",
        "\n",
        "# Ensure only 6 features are used for LSTM\n",
        "new_features = new_features[:6]  # Keep only the first 6 features\n",
        "\n",
        "# Scale the features\n",
        "scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "# Reshape to match LSTM input (1 sample, 1 time step, 6 features)\n",
        "X_new = np.array(scaled_features).reshape(1, 1, 6)\n",
        "\n",
        "# Make Prediction\n",
        "prediction = model.predict(X_new)[0][0]\n",
        "print(\"Prediction:\", prediction)\n",
        "\n",
        "# Generate Trading Signal\n",
        "if prediction > 0.2:\n",
        "    signal = \"BUY Signal ðŸš€\"\n",
        "elif prediction < -0.2:\n",
        "    signal = \"SELL Signal ðŸ”»\"\n",
        "else:\n",
        "    signal = \"NO TRADE âŒ\"\n",
        "\n",
        "# Output Required Data\n",
        "print(f\"Trading Signal: {signal}\")\n",
        "print(f\"Aggressive Buying/Selling (4H): {last_4h_delta}\")\n",
        "print(f\"Aggressive Buying/Selling (15M): {last_15m_delta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiEsFvko6poe",
        "outputId": "831adb2d-6543-4d5a-e033-a39f4635a12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45s/step\n",
            "Prediction: 0.0\n",
            "Trading Signal: NO TRADE âŒ\n",
            "Aggressive Buying/Selling (4H): -160.79989999999998\n",
            "Aggressive Buying/Selling (15M): -112.84189999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding more features like imbalance ratio and multiple assets"
      ],
      "metadata": {
        "id": "xuS8MLW0KTLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "\n",
        "# Initialize Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "    bids = order_book['bids'][:depth]\n",
        "    asks = order_book['asks'][:depth]\n",
        "    return bids, asks\n",
        "\n",
        "# Fetch Executed Trades\n",
        "def fetch_trade_data(symbol, since=None, limit=100):\n",
        "    trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "    df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Calculate Order Flow\n",
        "def analyze_aggressive_orders(trade_df, timeframe='4h'):\n",
        "    trade_df = trade_df.set_index('timestamp')\n",
        "    resampled = trade_df.resample(timeframe).agg({\n",
        "        'amount': 'sum', 'price': 'mean',\n",
        "        'side': lambda x: (x == 'buy').sum()\n",
        "    })\n",
        "\n",
        "    resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "    resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "    resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "    resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "    resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "    resampled['cumulative_delta'] = resampled['delta'].cumsum()\n",
        "\n",
        "    return resampled\n",
        "\n",
        "# Preprocess Order Book with Imbalance\n",
        "def preprocess_order_book(bids, asks):\n",
        "    bid_prices = np.array([bid[0] for bid in bids])\n",
        "    bid_sizes = np.array([bid[1] for bid in bids])\n",
        "    ask_prices = np.array([ask[0] for ask in asks])\n",
        "    ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "    spread = ask_prices[0] - bid_prices[0]\n",
        "    vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "    imbalance_ratio = np.sum(bid_sizes) / (np.sum(ask_sizes) + 1e-6)  # Avoid divide by zero\n",
        "\n",
        "    return [spread, vwap, imbalance_ratio]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    now = datetime.datetime.utcnow()\n",
        "    hour_of_day = now.hour / 23.0  # Normalize 0-1\n",
        "    day_of_week = now.weekday() / 6.0  # Normalize 0-1\n",
        "    return [hour_of_day, day_of_week]\n",
        "\n",
        "# Load & Scale Data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 6)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fetch Data for Multiple Assets\n",
        "symbols = [\"AVAX/USDT\", \"CRV/USDT\", \"NEAR/USDT\", \"LINK/USDT\", \"JUP/USDT\"]\n",
        "predictions = {}\n",
        "\n",
        "for symbol in symbols:\n",
        "    try:\n",
        "        # Fetch Order Book & Trades\n",
        "        bids, asks = fetch_order_book(symbol)\n",
        "        trade_data = fetch_trade_data(symbol)\n",
        "\n",
        "        # Aggressive Order Flow Analysis\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')\n",
        "\n",
        "        last_4h_delta = aggressive_orders_4h['delta'].iloc[-1]\n",
        "        last_4h_cvd = aggressive_orders_4h['cumulative_delta'].iloc[-1]\n",
        "\n",
        "        last_15m_delta = aggressive_orders_15m['delta'].iloc[-1]\n",
        "        last_15m_cvd = aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "\n",
        "        # Order Book Features + Aggressive Order Flow + Time Features\n",
        "        features = preprocess_order_book(bids, asks) + \\\n",
        "                   [last_4h_delta, last_15m_delta] + \\\n",
        "                   get_time_features()\n",
        "\n",
        "        # Scale Features\n",
        "        scaled_features = scaler.fit_transform([features])\n",
        "\n",
        "        # Reshape for LSTM\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 6)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"BUY ðŸš€\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"SELL ðŸ”»\"\n",
        "        else:\n",
        "            signal = \"NO TRADE âŒ\"\n",
        "\n",
        "        # Store Results\n",
        "        predictions[symbol] = {\n",
        "            \"Prediction\": prediction,\n",
        "            \"Signal\": signal,\n",
        "            \"Aggressive Buying/Selling (4H)\": last_4h_delta,\n",
        "            \"Aggressive Buying/Selling (15M)\": last_15m_delta\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        predictions[symbol] = {\"error\": str(e)}\n",
        "\n",
        "# Print Results\n",
        "for symbol, data in predictions.items():\n",
        "    print(f\"\\nðŸ”¹ {symbol}\")\n",
        "    if \"error\" in data:\n",
        "        print(f\"âš ï¸ Error: {data['error']}\")\n",
        "    else:\n",
        "        print(f\"ðŸ“Š Prediction: {data['Prediction']:.4f}\")\n",
        "        print(f\"ðŸ“ˆ Signal: {data['Signal']}\")\n",
        "        print(f\"ðŸ“Š Aggressive Order Flow (4H): {data['Aggressive Buying/Selling (4H)']:.2f}\")\n",
        "        print(f\"ðŸ“Š Aggressive Order Flow (15M): {data['Aggressive Buying/Selling (15M)']:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz-1vGnVKZMb",
        "outputId": "6495db7b-b779-4922-8553-28e5292b72c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ AVAX/USDT\n",
            "âš ï¸ Error: cannot reshape array of size 7 into shape (1,1,6)\n",
            "\n",
            "ðŸ”¹ CRV/USDT\n",
            "âš ï¸ Error: cannot reshape array of size 7 into shape (1,1,6)\n",
            "\n",
            "ðŸ”¹ NEAR/USDT\n",
            "âš ï¸ Error: cannot reshape array of size 7 into shape (1,1,6)\n",
            "\n",
            "ðŸ”¹ LINK/USDT\n",
            "âš ï¸ Error: cannot reshape array of size 7 into shape (1,1,6)\n",
            "\n",
            "ðŸ”¹ JUP/USDT\n",
            "âš ï¸ Error: cannot reshape array of size 7 into shape (1,1,6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "above code is good but has an error. I am not sure about the code below is with same features or not."
      ],
      "metadata": {
        "id": "8x8d48I-pYHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "    bids = order_book['bids'][:depth]  # Top bids\n",
        "    asks = order_book['asks'][:depth]  # Top asks\n",
        "    return bids, asks\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=100):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "    df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe='4h'):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    trade_df = trade_df.set_index('timestamp')\n",
        "    resampled = trade_df.resample(timeframe).agg({\n",
        "        'amount': 'sum', 'price': 'mean',\n",
        "        'side': lambda x: (x == 'buy').sum()\n",
        "    })\n",
        "\n",
        "    resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "    resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "    resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "    resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "    resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "    resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "    return resampled\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    bid_prices = np.array([bid[0] for bid in bids])\n",
        "    bid_sizes = np.array([bid[1] for bid in bids])\n",
        "    ask_prices = np.array([ask[0] for ask in asks])\n",
        "    ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "    spread = ask_prices[0] - bid_prices[0]\n",
        "    vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "    imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "    bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)  # New Feature\n",
        "\n",
        "    return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week\"\"\"\n",
        "    now = datetime.datetime.utcnow()\n",
        "    hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "    day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "    return [hour_of_day, day_of_week]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        # Get Aggressive Order Flow Analysis\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')\n",
        "\n",
        "        # Extract Latest Values\n",
        "        last_4h_delta = aggressive_orders_4h['delta'].iloc[-1]\n",
        "        last_4h_cvd = aggressive_orders_4h['cumulative_delta'].iloc[-1]\n",
        "        last_15m_delta = aggressive_orders_15m['delta'].iloc[-1]\n",
        "        last_15m_cvd = aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "\n",
        "        # Combine Features\n",
        "        new_features = preprocess_order_book(bids, asks) + [last_4h_delta, last_15m_delta] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Result\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {last_4h_delta:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {last_15m_delta:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"âš ï¸ Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAbP9iwLpfSR",
        "outputId": "602a32be-8241-4380-81c6-00e34445034a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
            "\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -101.95\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 4.52\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ CRV/USDT\n",
            "ðŸ“ˆ Prediction: nan\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 1982.10\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: nan\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ðŸ“ˆ Prediction: nan\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 587.64\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: nan\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "ðŸ”¹ LINK/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -59.46\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -28.08\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\n",
            "ðŸ”¹ JUP/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -174.40\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -174.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "daily weekly timeframes with bid ask amounts"
      ],
      "metadata": {
        "id": "_FaR5cCCyxld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from kucoin.client import Market\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Initialize KuCoin API client\n",
        "client = ccxt.kucoin()\n",
        "\n",
        "# Load LSTM Model\n",
        "model = load_model(\"lstm_model.h5\")  # Ensure this model is trained properly\n",
        "\n",
        "# Function to fetch order book data\n",
        "def fetch_order_book(symbol):\n",
        "    try:\n",
        "        data = client.get_part_order(symbol, limit=20)\n",
        "        bids = np.array([[float(price), float(size)] for price, size in data['bids']])\n",
        "        asks = np.array([[float(price), float(size)] for price, size in data['asks']])\n",
        "        return bids, asks\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching order book for {symbol}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to fetch trade data\n",
        "def fetch_trade_data(symbol, timeframe):\n",
        "    try:\n",
        "        end_time = int(time.time())\n",
        "        start_time = end_time - timeframe\n",
        "        trades = client.get_trade_histories(symbol)\n",
        "        trade_df = pd.DataFrame(trades)\n",
        "        trade_df['price'] = trade_df['price'].astype(float)\n",
        "        trade_df['size'] = trade_df['size'].astype(float)\n",
        "        trade_df['side'] = trade_df['side'].apply(lambda x: 1 if x == 'buy' else -1)\n",
        "        trade_df['timestamp'] = pd.to_datetime(trade_df['created_at'], unit='ms')\n",
        "        trade_df = trade_df[(trade_df['timestamp'] >= datetime.utcfromtimestamp(start_time)) &\n",
        "                             (trade_df['timestamp'] <= datetime.utcfromtimestamp(end_time))]\n",
        "        return trade_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching trade data for {symbol}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to calculate bid/ask volume and aggressive buying/selling\n",
        "def analyze_order_flow(trade_df):\n",
        "    if trade_df is None or trade_df.empty:\n",
        "        return 0, 0, 0\n",
        "\n",
        "    buy_volume = trade_df[trade_df['side'] == 1]['size'].sum()\n",
        "    sell_volume = trade_df[trade_df['side'] == -1]['size'].sum()\n",
        "    delta = buy_volume - sell_volume\n",
        "    return buy_volume, sell_volume, delta\n",
        "\n",
        "# Main loop\n",
        "symbols = [\"AVAX-USDT\", \"CRV-USDT\", \"NEAR-USDT\", \"LINK-USDT\", \"JUP-USDT\"]\n",
        "for symbol in symbols:\n",
        "    bids, asks = fetch_order_book(symbol)\n",
        "\n",
        "    # Get trade data for different timeframes\n",
        "    trade_15m = fetch_trade_data(symbol, 900)\n",
        "    trade_4h = fetch_trade_data(symbol, 14400)\n",
        "    trade_1d = fetch_trade_data(symbol, 86400)\n",
        "    trade_1w = fetch_trade_data(symbol, 604800)\n",
        "\n",
        "    # Analyze Order Flow\n",
        "    bid_15m, ask_15m, delta_15m = analyze_order_flow(trade_15m)\n",
        "    bid_4h, ask_4h, delta_4h = analyze_order_flow(trade_4h)\n",
        "    bid_1d, ask_1d, delta_1d = analyze_order_flow(trade_1d)\n",
        "    bid_1w, ask_1w, delta_1w = analyze_order_flow(trade_1w)\n",
        "\n",
        "    # Prepare LSTM input\n",
        "    if bids is not None and asks is not None:\n",
        "        feature_array = np.array([bids[:10, 1].sum(), asks[:10, 1].sum(), delta_4h, delta_15m, delta_1d, delta_1w])\n",
        "        feature_array = feature_array.reshape(1, 1, 6)  # Shape must match LSTM input\n",
        "        prediction = model.predict(feature_array)[0][0]\n",
        "    else:\n",
        "        prediction = 0  # Default if no data\n",
        "\n",
        "    # Determine Signal\n",
        "    if prediction > 0.2:\n",
        "        signal = \"ðŸš€ BUY Signal\"\n",
        "    elif prediction < -0.2:\n",
        "        signal = \"ðŸ”» SELL Signal\"\n",
        "    else:\n",
        "        signal = \"âŒ NO TRADE\"\n",
        "\n",
        "    # Print Results\n",
        "    print(f\"\\nðŸ”¹ {symbol}\")\n",
        "    print(f\"ðŸ“ˆ Prediction: {round(prediction, 4)}\")\n",
        "    print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "    print(f\"ðŸ“Š 15M Bid: {bid_15m} | 15M Ask: {ask_15m}\")\n",
        "    print(f\"ðŸ“Š 4H Bid: {bid_4h} | 4H Ask: {ask_4h}\")\n",
        "    print(f\"ðŸ“Š 1D Bid: {bid_1d} | 1D Ask: {ask_1d}\")\n",
        "    print(f\"ðŸ“Š 1W Bid: {bid_1w} | 1W Ask: {ask_1w}\")\n",
        "    time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "rwYx3zFny22r",
        "outputId": "9838dacf-582b-42a6-8fda-fefc34dff7ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'kucoin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-872c2bda286b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkucoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kucoin'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now this version has everything"
      ],
      "metadata": {
        "id": "rIcUtaVF3Ccx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "    bids = order_book['bids'][:depth]  # Top bids\n",
        "    asks = order_book['asks'][:depth]  # Top asks\n",
        "    return bids, asks\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "    df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe='4h'):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    trade_df = trade_df.set_index('timestamp')\n",
        "\n",
        "    resampled = trade_df.resample(timeframe).agg({\n",
        "        'amount': 'sum', 'price': 'mean',\n",
        "        'side': lambda x: (x == 'buy').sum()\n",
        "    })\n",
        "\n",
        "    resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "    resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "    resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "    resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "    resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "    resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "    return resampled\n",
        "\n",
        "# Process Bid-Ask Volume\n",
        "def process_bid_ask_volume(bids, asks):\n",
        "    \"\"\"Extract bid-ask volume metrics\"\"\"\n",
        "    bid_volume = sum([bid[0] * bid[1] for bid in bids])\n",
        "    ask_volume = sum([ask[0] * ask[1] for ask in asks])\n",
        "    bid_ask_ratio = bid_volume / ask_volume if ask_volume > 0 else 0\n",
        "\n",
        "    return bid_volume, ask_volume, bid_ask_ratio\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week\"\"\"\n",
        "    now = datetime.datetime.utcnow()\n",
        "    hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "    day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "    return [hour_of_day, day_of_week]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 9)),  # Updated to 9 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        # Get Aggressive Order Flow Analysis\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')\n",
        "\n",
        "        # Get Daily & Weekly Bid-Ask Volume\n",
        "        aggressive_orders_daily = analyze_aggressive_orders(trade_data, '1D')\n",
        "        aggressive_orders_weekly = analyze_aggressive_orders(trade_data, '1W')\n",
        "\n",
        "        # Extract Latest Values\n",
        "        last_4h_delta = aggressive_orders_4h['delta'].iloc[-1]\n",
        "        last_4h_cvd = aggressive_orders_4h['cumulative_delta'].iloc[-1]\n",
        "        last_15m_delta = aggressive_orders_15m['delta'].iloc[-1]\n",
        "        last_15m_cvd = aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "\n",
        "        daily_bid_volume = aggressive_orders_daily['buy_volume'].iloc[-1]\n",
        "        daily_ask_volume = aggressive_orders_daily['sell_volume'].iloc[-1]\n",
        "        weekly_bid_volume = aggressive_orders_weekly['buy_volume'].iloc[-1]\n",
        "        weekly_ask_volume = aggressive_orders_weekly['sell_volume'].iloc[-1]\n",
        "\n",
        "        # Extract Bid-Ask Volume Features\n",
        "        bid_volume, ask_volume, bid_ask_ratio = process_bid_ask_volume(bids, asks)\n",
        "\n",
        "        # Combine Features\n",
        "        new_features = [\n",
        "            last_4h_delta, last_15m_delta,\n",
        "            bid_volume, ask_volume, bid_ask_ratio,\n",
        "            daily_bid_volume, daily_ask_volume,\n",
        "            weekly_bid_volume, weekly_ask_volume\n",
        "        ] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 9 Features for LSTM\n",
        "        new_features = new_features[:9]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 9 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 9)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Result\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {last_4h_delta:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {last_15m_delta:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Bid Volume: {daily_bid_volume:.2f}, Daily Ask Volume: {daily_ask_volume:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Bid Volume: {weekly_bid_volume:.2f}, Weekly Ask Volume: {weekly_ask_volume:.2f}\")\n",
        "        print(f\"ðŸ“Š Order Book Bid/Ask Ratio: {bid_ask_ratio:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"âš ï¸ Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ObuWOr3HSD",
        "outputId": "bde9a1cc-4766-4659-c34f-def279020bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -122.01\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -122.01\n",
            "ðŸ“Š Daily Bid Volume: 188.98, Daily Ask Volume: 310.99\n",
            "ðŸ“Š Weekly Bid Volume: 188.98, Weekly Ask Volume: 310.99\n",
            "ðŸ“Š Order Book Bid/Ask Ratio: 0.71\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "ðŸ”¹ CRV/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 760.70\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 760.70\n",
            "ðŸ“Š Daily Bid Volume: 2262.40, Daily Ask Volume: 1501.70\n",
            "ðŸ“Š Weekly Bid Volume: 2262.40, Weekly Ask Volume: 1501.70\n",
            "ðŸ“Š Order Book Bid/Ask Ratio: 1.26\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 318.39\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 318.39\n",
            "ðŸ“Š Daily Bid Volume: 666.78, Daily Ask Volume: 348.38\n",
            "ðŸ“Š Weekly Bid Volume: 666.78, Weekly Ask Volume: 348.38\n",
            "ðŸ“Š Order Book Bid/Ask Ratio: 0.89\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "ðŸ”¹ LINK/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -424.64\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -424.64\n",
            "ðŸ“Š Daily Bid Volume: 202.52, Daily Ask Volume: 627.17\n",
            "ðŸ“Š Weekly Bid Volume: 202.52, Weekly Ask Volume: 627.17\n",
            "ðŸ“Š Order Book Bid/Ask Ratio: 1.53\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "ðŸ”¹ JUP/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 9737.52\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 2723.46\n",
            "ðŸ“Š Daily Bid Volume: 17023.31, Daily Ask Volume: 7285.79\n",
            "ðŸ“Š Weekly Bid Volume: 17023.31, Weekly Ask Volume: 7285.79\n",
            "ðŸ“Š Order Book Bid/Ask Ratio: 1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "different timeframes and different"
      ],
      "metadata": {
        "id": "UK-yki8v6XSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "    bids = order_book['bids'][:depth]  # Top bids\n",
        "    asks = order_book['asks'][:depth]  # Top asks\n",
        "    return bids, asks\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "    df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe='4h'):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    trade_df = trade_df.set_index('timestamp')\n",
        "    resampled = trade_df.resample(timeframe).agg({\n",
        "        'amount': 'sum', 'price': 'mean',\n",
        "        'side': lambda x: (x == 'buy').sum()\n",
        "    })\n",
        "\n",
        "    resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "    resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "    resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "    resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "    resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "    resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "    return resampled\n",
        "\n",
        "# Calculate Daily & Weekly Bid-Ask Volumes\n",
        "def calculate_bid_ask_volume(trade_df):\n",
        "    \"\"\"Calculate daily and weekly bid-ask volume separately\"\"\"\n",
        "    trade_df = trade_df.set_index('timestamp')\n",
        "\n",
        "    daily_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1D')['amount'].sum().iloc[-1]\n",
        "    daily_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1D')['amount'].sum().iloc[-1]\n",
        "\n",
        "    weekly_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1W')['amount'].sum().iloc[-1]\n",
        "    weekly_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1W')['amount'].sum().iloc[-1]\n",
        "\n",
        "    return daily_bid_volume, daily_ask_volume, weekly_bid_volume, weekly_ask_volume\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    bid_prices = np.array([bid[0] for bid in bids])\n",
        "    bid_sizes = np.array([bid[1] for bid in bids])\n",
        "    ask_prices = np.array([ask[0] for ask in asks])\n",
        "    ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "    spread = ask_prices[0] - bid_prices[0]\n",
        "    vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "    imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "    bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)  # New Feature\n",
        "\n",
        "    return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week\"\"\"\n",
        "    now = datetime.datetime.utcnow()\n",
        "    hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "    day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "    return [hour_of_day, day_of_week]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        # Get Aggressive Order Flow Analysis\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')\n",
        "\n",
        "        # Get Daily & Weekly Bid-Ask Volume\n",
        "        daily_bid, daily_ask, weekly_bid, weekly_ask = calculate_bid_ask_volume(trade_data)\n",
        "\n",
        "        # Extract Latest Values\n",
        "        last_4h_delta = aggressive_orders_4h['delta'].iloc[-1]\n",
        "        last_4h_cvd = aggressive_orders_4h['cumulative_delta'].iloc[-1]\n",
        "        last_15m_delta = aggressive_orders_15m['delta'].iloc[-1]\n",
        "        last_15m_cvd = aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "\n",
        "        # Combine Features\n",
        "        new_features = preprocess_order_book(bids, asks) + [last_4h_delta, last_15m_delta] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Result\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {last_4h_delta:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {last_15m_delta:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Bid Volume: {daily_bid:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Ask Volume: {daily_ask:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Bid Volume: {weekly_bid:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Ask Volume: {weekly_ask:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"âš ï¸ Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOnBFWBX6baM",
        "outputId": "a6b04f03-8fa0-4a91-9878-016c6dfaf7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -111.46\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -167.12\n",
            "ðŸ“Š Daily Bid Volume: 190.75\n",
            "ðŸ“Š Daily Ask Volume: 302.22\n",
            "ðŸ“Š Weekly Bid Volume: 190.75\n",
            "ðŸ“Š Weekly Ask Volume: 302.22\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "ðŸ”¹ CRV/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -903.59\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -1198.56\n",
            "ðŸ“Š Daily Bid Volume: 3033.31\n",
            "ðŸ“Š Daily Ask Volume: 3936.90\n",
            "ðŸ“Š Weekly Bid Volume: 3033.31\n",
            "ðŸ“Š Weekly Ask Volume: 3936.90\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -487.04\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -491.06\n",
            "ðŸ“Š Daily Bid Volume: 350.99\n",
            "ðŸ“Š Daily Ask Volume: 838.03\n",
            "ðŸ“Š Weekly Bid Volume: 350.99\n",
            "ðŸ“Š Weekly Ask Volume: 838.03\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "ðŸ”¹ LINK/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 24.00\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 24.00\n",
            "ðŸ“Š Daily Bid Volume: 102.44\n",
            "ðŸ“Š Daily Ask Volume: 78.44\n",
            "ðŸ“Š Weekly Bid Volume: 102.44\n",
            "ðŸ“Š Weekly Ask Volume: 78.44\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\n",
            "ðŸ”¹ JUP/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 10561.12\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 820.44\n",
            "ðŸ“Š Daily Bid Volume: 15889.94\n",
            "ðŸ“Š Daily Ask Volume: 5328.82\n",
            "ðŸ“Š Weekly Bid Volume: 15889.94\n",
            "ðŸ“Š Weekly Ask Volume: 5328.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "deepseek help below"
      ],
      "metadata": {
        "id": "xxxJ5W7n_jcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    try:\n",
        "        order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "        bids = order_book['bids'][:depth]  # Top bids\n",
        "        asks = order_book['asks'][:depth]  # Top asks\n",
        "        return bids, asks\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching order book for {symbol}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    try:\n",
        "        trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "        df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching trade data for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe='4h'):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    try:\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "        resampled = trade_df.resample(timeframe).agg({\n",
        "            'amount': 'sum', 'price': 'mean',\n",
        "            'side': lambda x: (x == 'buy').sum()\n",
        "        })\n",
        "\n",
        "        resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "        resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "        resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "        resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "        resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "        resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "        return resampled\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error analyzing aggressive orders: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Calculate Daily & Weekly Bid-Ask Volumes\n",
        "def calculate_bid_ask_volume(trade_df):\n",
        "    \"\"\"Calculate daily and weekly bid-ask volume separately\"\"\"\n",
        "    try:\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "\n",
        "        daily_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1D')['amount'].sum()\n",
        "        daily_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1D')['amount'].sum()\n",
        "\n",
        "        weekly_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1W')['amount'].sum()\n",
        "        weekly_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1W')['amount'].sum()\n",
        "\n",
        "        # Get the latest values\n",
        "        daily_bid = daily_bid_volume.iloc[-1] if not daily_bid_volume.empty else 0\n",
        "        daily_ask = daily_ask_volume.iloc[-1] if not daily_ask_volume.empty else 0\n",
        "        weekly_bid = weekly_bid_volume.iloc[-1] if not weekly_bid_volume.empty else 0\n",
        "        weekly_ask = weekly_ask_volume.iloc[-1] if not weekly_ask_volume.empty else 0\n",
        "\n",
        "        return daily_bid, daily_ask, weekly_bid, weekly_ask\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error calculating bid-ask volume: {e}\")\n",
        "        return 0, 0, 0, 0\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    try:\n",
        "        bid_prices = np.array([bid[0] for bid in bids])\n",
        "        bid_sizes = np.array([bid[1] for bid in bids])\n",
        "        ask_prices = np.array([ask[0] for ask in asks])\n",
        "        ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "        spread = ask_prices[0] - bid_prices[0]\n",
        "        vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "        imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "        bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)  # New Feature\n",
        "\n",
        "        return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error preprocessing order book: {e}\")\n",
        "        return [0, 0, 0, 0]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week\"\"\"\n",
        "    try:\n",
        "        now = datetime.datetime.utcnow()\n",
        "        hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "        day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "        return [hour_of_day, day_of_week]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error getting time features: {e}\")\n",
        "        return [0, 0]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        if trade_data.empty:\n",
        "            logging.warning(f\"No trade data found for {asset}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Get Aggressive Order Flow Analysis\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')\n",
        "\n",
        "        # Get Daily & Weekly Bid-Ask Volume\n",
        "        daily_bid, daily_ask, weekly_bid, weekly_ask = calculate_bid_ask_volume(trade_data)\n",
        "\n",
        "        # Extract Latest Values\n",
        "        last_4h_delta = aggressive_orders_4h['delta'].iloc[-1]\n",
        "        last_4h_cvd = aggressive_orders_4h['cumulative_delta'].iloc[-1]\n",
        "        last_15m_delta = aggressive_orders_15m['delta'].iloc[-1]\n",
        "        last_15m_cvd = aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "\n",
        "        # Combine Features\n",
        "        new_features = preprocess_order_book(bids, asks) + [last_4h_delta, last_15m_delta] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Result\n",
        "        logging.info(f\"\\nðŸ”¹ {asset}\")\n",
        "        logging.info(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        logging.info(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        logging.info(f\"ðŸ“Š 4H Aggressive Buying/Selling: {last_4h_delta:.2f}\")\n",
        "        logging.info(f\"ðŸ“Š 15M Aggressive Buying/Selling: {last_15m_delta:.2f}\")\n",
        "        logging.info(f\"ðŸ“Š Daily Bid Volume: {daily_bid:.2f}\")\n",
        "        logging.info(f\"ðŸ“Š Daily Ask Volume: {daily_ask:.2f}\")\n",
        "        logging.info(f\"ðŸ“Š Weekly Bid Volume: {weekly_bid:.2f}\")\n",
        "        logging.info(f\"ðŸ“Š Weekly Ask Volume: {weekly_ask:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"\\nðŸ”¹ {asset}\")\n",
        "        logging.error(f\"âš ï¸ Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPi3VW_y_liq",
        "outputId": "372acf3a-6567-4861-9988-08efd30e0689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after adding results in output"
      ],
      "metadata": {
        "id": "21qGLfI9AazX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    try:\n",
        "        order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "        bids = order_book['bids'][:depth]  # Top bids\n",
        "        asks = order_book['asks'][:depth]  # Top asks\n",
        "        return bids, asks\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching order book for {symbol}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    try:\n",
        "        trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "        df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching trade data for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    try:\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "        resampled = trade_df.resample(timeframe).agg({\n",
        "            'amount': 'sum', 'price': 'mean',\n",
        "            'side': lambda x: (x == 'buy').sum()\n",
        "        })\n",
        "\n",
        "        resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "        resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "        resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "        resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "        resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "        resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "        return resampled\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error analyzing aggressive orders for {timeframe}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Calculate Trade Volumes for Multiple Timeframes\n",
        "def calculate_trade_volumes(trade_df):\n",
        "    \"\"\"Calculate trade volumes for 1D, 1W, 4H, and 15M timeframes\"\"\"\n",
        "    try:\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "\n",
        "        # Daily and Weekly Volumes\n",
        "        daily_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1D')['amount'].sum().iloc[-1]\n",
        "        daily_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1D')['amount'].sum().iloc[-1]\n",
        "        weekly_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1W')['amount'].sum().iloc[-1]\n",
        "        weekly_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1W')['amount'].sum().iloc[-1]\n",
        "\n",
        "        # 4H and 15M Volumes\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_df, '4H')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_df, '15T')\n",
        "\n",
        "        return {\n",
        "            'daily_bid_volume': daily_bid_volume,\n",
        "            'daily_ask_volume': daily_ask_volume,\n",
        "            'weekly_bid_volume': weekly_bid_volume,\n",
        "            'weekly_ask_volume': weekly_ask_volume,\n",
        "            '4h_delta': aggressive_orders_4h['delta'].iloc[-1],\n",
        "            '4h_cvd': aggressive_orders_4h['cumulative_delta'].iloc[-1],\n",
        "            '15m_delta': aggressive_orders_15m['delta'].iloc[-1],\n",
        "            '15m_cvd': aggressive_orders_15m['cumulative_delta'].iloc[-1]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error calculating trade volumes: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    try:\n",
        "        bid_prices = np.array([bid[0] for bid in bids])\n",
        "        bid_sizes = np.array([bid[1] for bid in bids])\n",
        "        ask_prices = np.array([ask[0] for ask in asks])\n",
        "        ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "        spread = ask_prices[0] - bid_prices[0]\n",
        "        vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "        imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "        bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)  # New Feature\n",
        "\n",
        "        return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error preprocessing order book: {e}\")\n",
        "        return [0, 0, 0, 0]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week\"\"\"\n",
        "    try:\n",
        "        now = datetime.datetime.utcnow()\n",
        "        hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "        day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "        return [hour_of_day, day_of_week]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error getting time features: {e}\")\n",
        "        return [0, 0]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        if trade_data.empty:\n",
        "            logging.warning(f\"No trade data found for {asset}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Calculate Trade Volumes and Aggressive Orders\n",
        "        trade_volumes = calculate_trade_volumes(trade_data)\n",
        "\n",
        "        # Combine Features for LSTM\n",
        "        new_features = preprocess_order_book(bids, asks) + [trade_volumes['4h_delta'], trade_volumes['15m_delta']] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Results\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {trade_volumes['4h_delta']:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {trade_volumes['15m_delta']:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Bid Volume: {trade_volumes['daily_bid_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Ask Volume: {trade_volumes['daily_ask_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Bid Volume: {trade_volumes['weekly_bid_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Ask Volume: {trade_volumes['weekly_ask_volume']:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"\\nðŸ”¹ {asset}\")\n",
        "        logging.error(f\"âš ï¸ Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjZi7SSFAc_j",
        "outputId": "90f6150a-d1bd-4456-9d5b-158d18790fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "ERROR:root:Error analyzing aggressive orders for 4H: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error calculating trade volumes: 'delta'\n",
            "ERROR:root:\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error analyzing aggressive orders for 4H: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error calculating trade volumes: 'delta'\n",
            "ERROR:root:\n",
            "ðŸ”¹ CRV/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error analyzing aggressive orders for 4H: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error calculating trade volumes: 'delta'\n",
            "ERROR:root:\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error analyzing aggressive orders for 4H: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error calculating trade volumes: 'delta'\n",
            "ERROR:root:\n",
            "ðŸ”¹ LINK/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error analyzing aggressive orders for 4H: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: \"None of ['timestamp'] are in the columns\"\n",
            "ERROR:root:Error calculating trade volumes: 'delta'\n",
            "ERROR:root:\n",
            "ðŸ”¹ JUP/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    try:\n",
        "        order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "        bids = order_book['bids'][:depth]  # Top bids\n",
        "        asks = order_book['asks'][:depth]  # Top asks\n",
        "        return bids, asks\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching order book for {symbol}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    try:\n",
        "        trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "        df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching trade data for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe):\n",
        "    \"\"\"Analyze buy vs. sell pressure over a given timeframe\"\"\"\n",
        "    try:\n",
        "        if 'timestamp' not in trade_df.columns:\n",
        "            raise ValueError(\"Column 'timestamp' not found in trade data.\")\n",
        "\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "        resampled = trade_df.resample(timeframe).agg({\n",
        "            'amount': 'sum', 'price': 'mean',\n",
        "            'side': lambda x: (x == 'buy').sum()\n",
        "        })\n",
        "\n",
        "        resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "        resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "\n",
        "        resampled['buy_volume'] = trade_df[trade_df['side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "        resampled['sell_volume'] = trade_df[trade_df['side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "        resampled['delta'] = resampled['buy_volume'] - resampled['sell_volume']\n",
        "        resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "        return resampled\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error analyzing aggressive orders for {timeframe}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Calculate Trade Volumes for Multiple Timeframes\n",
        "def calculate_trade_volumes(trade_df):\n",
        "    \"\"\"Calculate trade volumes for 1D, 1W, 4H, and 15M timeframes\"\"\"\n",
        "    try:\n",
        "        if trade_df.empty:\n",
        "            raise ValueError(\"Trade data is empty.\")\n",
        "\n",
        "        if 'timestamp' not in trade_df.columns:\n",
        "            raise ValueError(\"Column 'timestamp' not found in trade data.\")\n",
        "\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "\n",
        "        # Daily and Weekly Volumes\n",
        "        daily_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1D')['amount'].sum().iloc[-1]\n",
        "        daily_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1D')['amount'].sum().iloc[-1]\n",
        "        weekly_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1W')['amount'].sum().iloc[-1]\n",
        "        weekly_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1W')['amount'].sum().iloc[-1]\n",
        "\n",
        "        # 4H and 15M Volumes\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_df, '4H')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_df, '15T')\n",
        "\n",
        "        return {\n",
        "            'daily_bid_volume': daily_bid_volume,\n",
        "            'daily_ask_volume': daily_ask_volume,\n",
        "            'weekly_bid_volume': weekly_bid_volume,\n",
        "            'weekly_ask_volume': weekly_ask_volume,\n",
        "            '4h_delta': aggressive_orders_4h['delta'].iloc[-1] if not aggressive_orders_4h.empty else 0,\n",
        "            '4h_cvd': aggressive_orders_4h['cumulative_delta'].iloc[-1] if not aggressive_orders_4h.empty else 0,\n",
        "            '15m_delta': aggressive_orders_15m['delta'].iloc[-1] if not aggressive_orders_15m.empty else 0,\n",
        "            '15m_cvd': aggressive_orders_15m['cumulative_delta'].iloc[-1] if not aggressive_orders_15m.empty else 0\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error calculating trade volumes: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    try:\n",
        "        bid_prices = np.array([bid[0] for bid in bids])\n",
        "        bid_sizes = np.array([bid[1] for bid in bids])\n",
        "        ask_prices = np.array([ask[0] for ask in asks])\n",
        "        ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "        spread = ask_prices[0] - bid_prices[0]\n",
        "        vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "        imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "        bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)  # New Feature\n",
        "\n",
        "        return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error preprocessing order book: {e}\")\n",
        "        return [0, 0, 0, 0]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week\"\"\"\n",
        "    try:\n",
        "        now = datetime.datetime.utcnow()\n",
        "        hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "        day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "        return [hour_of_day, day_of_week]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error getting time features: {e}\")\n",
        "        return [0, 0]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        if trade_data.empty:\n",
        "            logging.warning(f\"No trade data found for {asset}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Debugging: Log the first few rows of trade data\n",
        "        logging.info(f\"Trade data for {asset}:\")\n",
        "        logging.info(trade_data.head())\n",
        "\n",
        "        # Calculate Trade Volumes and Aggressive Orders\n",
        "        trade_volumes = calculate_trade_volumes(trade_data)\n",
        "\n",
        "        # Combine Features for LSTM\n",
        "        new_features = preprocess_order_book(bids, asks) + [trade_volumes['4h_delta'], trade_volumes['15m_delta']] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Results\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {trade_volumes['4h_delta']:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {trade_volumes['15m_delta']:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Bid Volume: {trade_volumes['daily_bid_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Ask Volume: {trade_volumes['daily_ask_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Bid Volume: {trade_volumes['weekly_bid_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Ask Volume: {trade_volumes['weekly_ask_volume']:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"\\nðŸ”¹ {asset}\")\n",
        "        logging.error(f\"âš ï¸ Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n-O-7vrBGc4",
        "outputId": "b5a74e39-f296-4541-f31f-b2cfb1b8d77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "ERROR:root:Error analyzing aggressive orders for 4H: Column 'timestamp' not found in trade data.\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: Column 'timestamp' not found in trade data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step\n",
            "\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š Daily Bid Volume: 276.78\n",
            "ðŸ“Š Daily Ask Volume: 352.53\n",
            "ðŸ“Š Weekly Bid Volume: 276.78\n",
            "ðŸ“Š Weekly Ask Volume: 352.53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error analyzing aggressive orders for 4H: Column 'timestamp' not found in trade data.\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: Column 'timestamp' not found in trade data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "\n",
            "ðŸ”¹ CRV/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š Daily Bid Volume: 6973.07\n",
            "ðŸ“Š Daily Ask Volume: 14709.85\n",
            "ðŸ“Š Weekly Bid Volume: 6973.07\n",
            "ðŸ“Š Weekly Ask Volume: 14709.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error analyzing aggressive orders for 4H: Column 'timestamp' not found in trade data.\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: Column 'timestamp' not found in trade data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š Daily Bid Volume: 2032.02\n",
            "ðŸ“Š Daily Ask Volume: 1525.36\n",
            "ðŸ“Š Weekly Bid Volume: 2032.02\n",
            "ðŸ“Š Weekly Ask Volume: 1525.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error analyzing aggressive orders for 4H: Column 'timestamp' not found in trade data.\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: Column 'timestamp' not found in trade data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "ðŸ”¹ LINK/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š Daily Bid Volume: 133.62\n",
            "ðŸ“Š Daily Ask Volume: 125.35\n",
            "ðŸ“Š Weekly Bid Volume: 133.62\n",
            "ðŸ“Š Weekly Ask Volume: 125.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error analyzing aggressive orders for 4H: Column 'timestamp' not found in trade data.\n",
            "ERROR:root:Error analyzing aggressive orders for 15T: Column 'timestamp' not found in trade data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "ðŸ”¹ JUP/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 0.00\n",
            "ðŸ“Š Daily Bid Volume: 7991.86\n",
            "ðŸ“Š Daily Ask Volume: 4221.99\n",
            "ðŸ“Š Weekly Bid Volume: 7991.86\n",
            "ðŸ“Š Weekly Ask Volume: 4221.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    try:\n",
        "        order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "        bids = order_book['bids'][:depth]  # Top bids\n",
        "        asks = order_book['asks'][:depth]  # Top asks\n",
        "        return bids, asks\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching order book for {symbol}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    try:\n",
        "        trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "        df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching trade data for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, bids, asks, timeframe):\n",
        "    \"\"\"Analyze aggressive buying and selling based on order book data\"\"\"\n",
        "    try:\n",
        "        if trade_df.empty:\n",
        "            raise ValueError(\"Trade data is empty.\")\n",
        "\n",
        "        # Get best bid and ask prices\n",
        "        best_bid = bids[0][0] if bids else None\n",
        "        best_ask = asks[0][0] if asks else None\n",
        "\n",
        "        if not best_bid or not best_ask:\n",
        "            raise ValueError(\"No bid or ask prices found in the order book.\")\n",
        "\n",
        "        # Classify trades as aggressive buys or sells\n",
        "        trade_df['aggressive_side'] = trade_df.apply(\n",
        "            lambda row: 'buy' if row['price'] == best_ask else ('sell' if row['price'] == best_bid else None),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Filter out non-aggressive trades\n",
        "        aggressive_trades = trade_df.dropna(subset=['aggressive_side'])\n",
        "\n",
        "        if aggressive_trades.empty:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Resample by timeframe\n",
        "        aggressive_trades = aggressive_trades.set_index('timestamp')\n",
        "        resampled = aggressive_trades.resample(timeframe).agg({\n",
        "            'amount': 'sum',\n",
        "            'aggressive_side': lambda x: (x == 'buy').sum()\n",
        "        })\n",
        "\n",
        "        resampled.rename(columns={'aggressive_side': 'aggressive_buy_count'}, inplace=True)\n",
        "        resampled['aggressive_sell_count'] = len(aggressive_trades) - resampled['aggressive_buy_count']\n",
        "\n",
        "        resampled['aggressive_buy_volume'] = aggressive_trades[aggressive_trades['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "        resampled['aggressive_sell_volume'] = aggressive_trades[aggressive_trades['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['amount'].sum()\n",
        "\n",
        "        resampled['delta'] = resampled['aggressive_buy_volume'] - resampled['aggressive_sell_volume']\n",
        "        resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "        return resampled\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error analyzing aggressive orders for {timeframe}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Calculate Trade Volumes for Multiple Timeframes\n",
        "def calculate_trade_volumes(trade_df, bids, asks):\n",
        "    \"\"\"Calculate trade volumes for 1D, 1W, 4H, and 15M timeframes\"\"\"\n",
        "    try:\n",
        "        if trade_df.empty:\n",
        "            raise ValueError(\"Trade data is empty.\")\n",
        "\n",
        "        # Daily and Weekly Volumes\n",
        "        daily_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1D')['amount'].sum().iloc[-1]\n",
        "        daily_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1D')['amount'].sum().iloc[-1]\n",
        "        weekly_bid_volume = trade_df[trade_df['side'] == 'buy'].resample('1W')['amount'].sum().iloc[-1]\n",
        "        weekly_ask_volume = trade_df[trade_df['side'] == 'sell'].resample('1W')['amount'].sum().iloc[-1]\n",
        "\n",
        "        # 4H and 15M Aggressive Orders\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_df, bids, asks, '4H')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_df, bids, asks, '15T')\n",
        "\n",
        "        return {\n",
        "            'daily_bid_volume': daily_bid_volume,\n",
        "            'daily_ask_volume': daily_ask_volume,\n",
        "            'weekly_bid_volume': weekly_bid_volume,\n",
        "            'weekly_ask_volume': weekly_ask_volume,\n",
        "            '4h_delta': aggressive_orders_4h['delta'].iloc[-1] if not aggressive_orders_4h.empty else 0,\n",
        "            '4h_cvd': aggressive_orders_4h['cumulative_delta'].iloc[-1] if not aggressive_orders_4h.empty else 0,\n",
        "            '15m_delta': aggressive_orders_15m['delta'].iloc[-1] if not aggressive_orders_15m.empty else 0,\n",
        "            '15m_cvd': aggressive_orders_15m['cumulative_delta'].iloc[-1] if not aggressive_orders_15m.empty else 0\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error calculating trade volumes: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book\"\"\"\n",
        "    try:\n",
        "        bid_prices = np.array([bid[0] for bid in bids])\n",
        "        bid_sizes = np.array([bid[1] for bid in bids])\n",
        "        ask_prices = np.array([ask[0] for ask in asks])\n",
        "        ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "        spread = ask_prices[0] - bid_prices[0]\n",
        "        vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "        imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "        bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)  # New Feature\n",
        "\n",
        "        return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error preprocessing order book: {e}\")\n",
        "        return [0, 0, 0, 0]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week\"\"\"\n",
        "    try:\n",
        "        now = datetime.datetime.utcnow()\n",
        "        hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "        day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "        return [hour_of_day, day_of_week]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error getting time features: {e}\")\n",
        "        return [0, 0]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        if trade_data.empty:\n",
        "            logging.warning(f\"No trade data found for {asset}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Debugging: Log the first few rows of trade data\n",
        "        logging.info(f\"Trade data for {asset}:\")\n",
        "        logging.info(trade_data.head())\n",
        "\n",
        "        # Calculate Trade Volumes and Aggressive Orders\n",
        "        trade_volumes = calculate_trade_volumes(trade_data, bids, asks)\n",
        "\n",
        "        # Combine Features for LSTM\n",
        "        new_features = preprocess_order_book(bids, asks) + [trade_volumes['4h_delta'], trade_volumes['15m_delta']] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Results\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {trade_volumes['4h_delta']:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {trade_volumes['15m_delta']:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Bid Volume: {trade_volumes['daily_bid_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Daily Ask Volume: {trade_volumes['daily_ask_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Bid Volume: {trade_volumes['weekly_bid_volume']:.2f}\")\n",
        "        print(f\"ðŸ“Š Weekly Ask Volume: {trade_volumes['weekly_ask_volume']:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"\\nðŸ”¹ {asset}\")\n",
        "        logging.error(f\"âš ï¸ Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DioDlEbQCo9a",
        "outputId": "a6d9ed2a-63ea-4fc4-d979-d8b129c1c3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "ERROR:root:Error calculating trade volumes: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error calculating trade volumes: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:\n",
            "ðŸ”¹ CRV/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error calculating trade volumes: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error calculating trade volumes: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:\n",
            "ðŸ”¹ LINK/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n",
            "ERROR:root:Error calculating trade volumes: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:\n",
            "ðŸ”¹ JUP/USDT\n",
            "ERROR:root:âš ï¸ Error: '4h_delta'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=20):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin\"\"\"\n",
        "    try:\n",
        "        order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "        bids = order_book['bids'][:depth]  # Top bids\n",
        "        asks = order_book['asks'][:depth]  # Top asks\n",
        "        return bids, asks\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching order book for {symbol}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin\"\"\"\n",
        "    try:\n",
        "        trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "        df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching trade data for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Classify Aggressive Orders with Trade Size Weighting\n",
        "def classify_aggressive_orders(trade_df, bids, asks, tolerance=0.001):\n",
        "    \"\"\"Classify trades as aggressive buys or sells based on a tolerance threshold and weight by trade size.\"\"\"\n",
        "    if trade_df.empty or not bids or not asks:\n",
        "        return trade_df\n",
        "\n",
        "    best_bid = bids[0][0]\n",
        "    best_ask = asks[0][0]\n",
        "\n",
        "    trade_df['aggressive_side'] = trade_df.apply(\n",
        "        lambda row: 'buy' if abs(row['price'] - best_ask) <= best_ask * tolerance else (\n",
        "            'sell' if abs(row['price'] - best_bid) <= best_bid * tolerance else None\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Weight aggressive orders by trade size\n",
        "    trade_df['weighted_amount'] = trade_df['amount'] * trade_df['price']\n",
        "    return trade_df\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe):\n",
        "    \"\"\"Analyze aggressive buying and selling over a given timeframe.\"\"\"\n",
        "    try:\n",
        "        if trade_df.empty:\n",
        "            raise ValueError(\"Trade data is empty.\")\n",
        "\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "        resampled = trade_df.resample(timeframe).agg({\n",
        "            'weighted_amount': 'sum',  # Weighted by trade size\n",
        "            'aggressive_side': lambda x: (x == 'buy').sum()\n",
        "        })\n",
        "\n",
        "        resampled.rename(columns={'aggressive_side': 'aggressive_buy_count'}, inplace=True)\n",
        "        resampled['aggressive_sell_count'] = len(trade_df) - resampled['aggressive_buy_count']\n",
        "\n",
        "        resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
        "        resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
        "\n",
        "        resampled['delta'] = resampled['aggressive_buy_volume'] - resampled['aggressive_sell_volume']\n",
        "        resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "        return resampled\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error analyzing aggressive orders for {timeframe}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Calculate Order Book Depth\n",
        "def calculate_order_book_depth(bids, asks, depth=5):\n",
        "    \"\"\"Calculate total volume at different price levels (e.g., top 5 bids/asks).\"\"\"\n",
        "    try:\n",
        "        bid_volumes = [bid[1] for bid in bids[:depth]]\n",
        "        ask_volumes = [ask[1] for ask in asks[:depth]]\n",
        "        return sum(bid_volumes), sum(ask_volumes)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error calculating order book depth: {e}\")\n",
        "        return 0, 0\n",
        "\n",
        "# Calculate Order Flow Imbalance\n",
        "def calculate_order_flow_imbalance(trade_df, timeframe='1H'):\n",
        "    \"\"\"Calculate the ratio of buy vs. sell market orders over a short period.\"\"\"\n",
        "    try:\n",
        "        if trade_df.empty:\n",
        "            raise ValueError(\"Trade data is empty.\")\n",
        "\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "        resampled = trade_df.resample(timeframe).agg({\n",
        "            'side': lambda x: (x == 'buy').sum()\n",
        "        })\n",
        "\n",
        "        resampled.rename(columns={'side': 'buy_count'}, inplace=True)\n",
        "        resampled['sell_count'] = len(trade_df) - resampled['buy_count']\n",
        "        resampled['imbalance'] = resampled['buy_count'] / (resampled['buy_count'] + resampled['sell_count'])\n",
        "\n",
        "        return resampled['imbalance'].iloc[-1]  # Latest imbalance value\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error calculating order flow imbalance: {e}\")\n",
        "        return 0\n",
        "\n",
        "# Identify Liquidity Zones\n",
        "def identify_liquidity_zones(bids, asks, threshold=0.1):\n",
        "    \"\"\"Identify areas of high liquidity (large bid/ask clusters).\"\"\"\n",
        "    try:\n",
        "        bid_prices = [bid[0] for bid in bids]\n",
        "        bid_volumes = [bid[1] for bid in bids]\n",
        "        ask_prices = [ask[0] for ask in asks]\n",
        "        ask_volumes = [ask[1] for ask in asks]\n",
        "\n",
        "        # Find zones where volume exceeds a threshold\n",
        "        bid_liquidity_zones = [price for price, vol in zip(bid_prices, bid_volumes) if vol > threshold]\n",
        "        ask_liquidity_zones = [price for price, vol in zip(ask_prices, ask_volumes) if vol > threshold]\n",
        "\n",
        "        return bid_liquidity_zones, ask_liquidity_zones\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error identifying liquidity zones: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book.\"\"\"\n",
        "    try:\n",
        "        bid_prices = np.array([bid[0] for bid in bids])\n",
        "        bid_sizes = np.array([bid[1] for bid in bids])\n",
        "        ask_prices = np.array([ask[0] for ask in asks])\n",
        "        ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "        spread = ask_prices[0] - bid_prices[0]\n",
        "        vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "        imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "        bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)\n",
        "\n",
        "        return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error preprocessing order book: {e}\")\n",
        "        return [0, 0, 0, 0]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week.\"\"\"\n",
        "    try:\n",
        "        now = datetime.datetime.utcnow()\n",
        "        hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "        day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "        return [hour_of_day, day_of_week]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error getting time features: {e}\")\n",
        "        return [0, 0]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset)\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        if trade_data.empty:\n",
        "            logging.warning(f\"No trade data found for {asset}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Classify Aggressive Orders\n",
        "        trade_data = classify_aggressive_orders(trade_data, bids, asks)\n",
        "\n",
        "        # Calculate Trade Volumes and Aggressive Orders\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4H')\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15T')\n",
        "\n",
        "        # Calculate Order Book Depth\n",
        "        bid_depth, ask_depth = calculate_order_book_depth(bids, asks, depth=5)\n",
        "\n",
        "        # Calculate Order Flow Imbalance\n",
        "        order_flow_imbalance = calculate_order_flow_imbalance(trade_data, timeframe='1H')\n",
        "\n",
        "        # Identify Liquidity Zones\n",
        "        bid_liquidity_zones, ask_liquidity_zones = identify_liquidity_zones(bids, asks, threshold=0.1)\n",
        "\n",
        "        # Combine Features for LSTM\n",
        "        new_features = preprocess_order_book(bids, asks) + [\n",
        "            aggressive_orders_4h['delta'].iloc[-1] if not aggressive_orders_4h.empty else 0,\n",
        "            aggressive_orders_15m['delta'].iloc[-1] if not aggressive_orders_15m.empty else 0,\n",
        "            order_flow_imbalance\n",
        "        ] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Results\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {aggressive_orders_4h['delta'].iloc[-1]:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {aggressive_orders_15m['delta'].iloc[-1]:.2f}\")\n",
        "        print(f\"ðŸ“Š Order Book Depth (Top 5 Bids/Asks): {bid_depth:.2f} / {ask_depth:.2f}\")\n",
        "        print(f\"ðŸ“Š Order Flow Imbalance: {order_flow_imbalance:.2f}\")\n",
        "        print(f\"ðŸ“Š Bid Liquidity Zones: {bid_liquidity_zones}\")\n",
        "        print(f\"ðŸ“Š Ask Liquidity Zones: {ask_liquidity_zones}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"\\nðŸ”¹ {asset}\")\n",
        "        logging.error(f\"âš ï¸ Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvr1ZuxbHTVK",
        "outputId": "7b71fd90-abb1-4ac1-93fb-6a65953c0327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:107: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ðŸ“ˆ Prediction: nan\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: nan\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: nan\n",
            "ðŸ“Š Order Book Depth (Top 5 Bids/Asks): 40.36 / 97.96\n",
            "ðŸ“Š Order Flow Imbalance: 0.50\n",
            "ðŸ“Š Bid Liquidity Zones: [24.537, 24.536, 24.535, 24.534, 24.533, 24.532, 24.531, 24.53, 24.528, 24.527, 24.526, 24.525, 24.523, 24.522, 24.521, 24.519, 24.518, 24.516, 24.515, 24.514]\n",
            "ðŸ“Š Ask Liquidity Zones: [24.539, 24.541, 24.542, 24.543, 24.544, 24.545, 24.548, 24.549, 24.55, 24.551, 24.552, 24.559, 24.56, 24.561, 24.562, 24.563, 24.564, 24.565, 24.567, 24.568]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:107: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ CRV/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 20172.25\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 3216.41\n",
            "ðŸ“Š Order Book Depth (Top 5 Bids/Asks): 16899.41 / 9095.49\n",
            "ðŸ“Š Order Flow Imbalance: 0.30\n",
            "ðŸ“Š Bid Liquidity Zones: [0.5128, 0.5127, 0.5126, 0.5125, 0.5124, 0.5123, 0.5122, 0.5121, 0.512, 0.5119, 0.5118, 0.5117, 0.5116, 0.5115, 0.5114, 0.5113, 0.5112, 0.5111, 0.511, 0.5109]\n",
            "ðŸ“Š Ask Liquidity Zones: [0.5131, 0.5132, 0.5133, 0.5134, 0.5135, 0.5136, 0.5137, 0.5138, 0.5139, 0.514, 0.5141, 0.5142, 0.5144, 0.5145, 0.5146, 0.5147, 0.5148, 0.5149, 0.515, 0.5151]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:107: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ðŸ“ˆ Prediction: nan\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: nan\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: nan\n",
            "ðŸ“Š Order Book Depth (Top 5 Bids/Asks): 240.00 / 628.45\n",
            "ðŸ“Š Order Flow Imbalance: 0.42\n",
            "ðŸ“Š Bid Liquidity Zones: [3.2332, 3.233, 3.2321, 3.232, 3.2317, 3.2316, 3.2313, 3.2312, 3.231, 3.2309, 3.2308, 3.2307, 3.2306, 3.2305, 3.2294, 3.2293, 3.2292, 3.2291, 3.229, 3.2289]\n",
            "ðŸ“Š Ask Liquidity Zones: [3.2333, 3.2334, 3.2336, 3.2337, 3.234, 3.2341, 3.235, 3.2354, 3.2355, 3.2359, 3.2364, 3.2365, 3.2367, 3.2368, 3.2373, 3.2374, 3.2377, 3.2379, 3.2384, 3.2386]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:107: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ LINK/USDT\n",
            "ðŸ“ˆ Prediction: nan\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: nan\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: nan\n",
            "ðŸ“Š Order Book Depth (Top 5 Bids/Asks): 95.95 / 120.88\n",
            "ðŸ“Š Order Flow Imbalance: 0.48\n",
            "ðŸ“Š Bid Liquidity Zones: [18.308, 18.3041, 18.3014, 18.3002, 18.3001, 18.2995, 18.2985, 18.298, 18.2978, 18.297, 18.2969, 18.2956, 18.2949, 18.2948, 18.2944, 18.2937, 18.2923, 18.2922, 18.292, 18.2918]\n",
            "ðŸ“Š Ask Liquidity Zones: [18.3093, 18.3094, 18.3127, 18.3128, 18.3129, 18.313, 18.3132, 18.3134, 18.3141, 18.3145, 18.315, 18.3151, 18.3152, 18.3158, 18.3163, 18.3186, 18.3187, 18.321, 18.3211, 18.3212]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "ðŸ”¹ JUP/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 3334.84\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 3334.84\n",
            "ðŸ“Š Order Book Depth (Top 5 Bids/Asks): 4037.10 / 5859.53\n",
            "ðŸ“Š Order Flow Imbalance: 0.33\n",
            "ðŸ“Š Bid Liquidity Zones: [0.8298, 0.8297, 0.8296, 0.8295, 0.8294, 0.8293, 0.8292, 0.8291, 0.829, 0.8289, 0.8288, 0.8287, 0.8286, 0.8285, 0.8284, 0.8283, 0.8282, 0.8281, 0.828, 0.8279]\n",
            "ðŸ“Š Ask Liquidity Zones: [0.8299, 0.83, 0.8301, 0.8302, 0.8303, 0.8304, 0.8305, 0.8306, 0.8307, 0.8308, 0.8309, 0.831, 0.8311, 0.8312, 0.8313, 0.8314, 0.8315, 0.8317, 0.8318, 0.8319]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:69: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n",
            "<ipython-input-11-b14da87c0cea>:77: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:78: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
            "<ipython-input-11-b14da87c0cea>:107: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  resampled = trade_df.resample(timeframe).agg({\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Initialize KuCoin Exchange\n",
        "exchange = ccxt.kucoin()\n",
        "\n",
        "# Fetch Level 2 Order Book\n",
        "def fetch_order_book(symbol, depth=100):\n",
        "    \"\"\"Fetch bid-ask Level 2 order book data from KuCoin.\"\"\"\n",
        "    try:\n",
        "        order_book = exchange.fetch_order_book(symbol, limit=depth)\n",
        "        bids = order_book['bids'][:depth]  # Top bids\n",
        "        asks = order_book['asks'][:depth]  # Top asks\n",
        "        return bids, asks\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching order book for {symbol}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Fetch Executed Trade Data\n",
        "def fetch_trade_data(symbol, since=None, limit=1000):\n",
        "    \"\"\"Fetch executed market orders from KuCoin.\"\"\"\n",
        "    try:\n",
        "        trades = exchange.fetch_trades(symbol, since=since, limit=limit)\n",
        "        df = pd.DataFrame(trades, columns=['timestamp', 'price', 'amount', 'side'])\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching trade data for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Classify Aggressive Orders with Trade Size Weighting\n",
        "def classify_aggressive_orders(trade_df, bids, asks, tolerance=0.001):\n",
        "    \"\"\"Classify trades as aggressive buys or sells based on a tolerance threshold and weight by trade size.\"\"\"\n",
        "    if trade_df.empty or not bids or not asks:\n",
        "        return trade_df\n",
        "\n",
        "    best_bid = bids[0][0] if bids else None\n",
        "    best_ask = asks[0][0] if asks else None\n",
        "\n",
        "    if not best_bid or not best_ask:\n",
        "        return trade_df\n",
        "\n",
        "    # Classify aggressive orders\n",
        "    trade_df['aggressive_side'] = trade_df.apply(\n",
        "        lambda row: 'buy' if abs(row['price'] - best_ask) <= best_ask * tolerance else (\n",
        "            'sell' if abs(row['price'] - best_bid) <= best_bid * tolerance else None\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Weight aggressive orders by trade size\n",
        "    trade_df['weighted_amount'] = trade_df['amount'] * trade_df['price']\n",
        "    return trade_df\n",
        "\n",
        "# Analyze Aggressive Buying & Selling\n",
        "def analyze_aggressive_orders(trade_df, timeframe):\n",
        "    \"\"\"Analyze aggressive buying and selling over a given timeframe.\"\"\"\n",
        "    try:\n",
        "        if trade_df.empty:\n",
        "            raise ValueError(\"Trade data is empty.\")\n",
        "\n",
        "        trade_df = trade_df.set_index('timestamp')\n",
        "        resampled = trade_df.resample(timeframe).agg({\n",
        "            'weighted_amount': 'sum',  # Weighted by trade size\n",
        "            'aggressive_side': lambda x: (x == 'buy').sum()\n",
        "        })\n",
        "\n",
        "        resampled.rename(columns={'aggressive_side': 'aggressive_buy_count'}, inplace=True)\n",
        "        resampled['aggressive_sell_count'] = len(trade_df) - resampled['aggressive_buy_count']\n",
        "\n",
        "        resampled['aggressive_buy_volume'] = trade_df[trade_df['aggressive_side'] == 'buy'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
        "        resampled['aggressive_sell_volume'] = trade_df[trade_df['aggressive_side'] == 'sell'].groupby(pd.Grouper(freq=timeframe))['weighted_amount'].sum()\n",
        "\n",
        "        resampled['delta'] = resampled['aggressive_buy_volume'] - resampled['aggressive_sell_volume']\n",
        "        resampled['cumulative_delta'] = resampled['delta'].cumsum()  # CVD\n",
        "\n",
        "        return resampled\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error analyzing aggressive orders for {timeframe}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Calculate Order Book Depth (Top 100 Bids/Asks)\n",
        "def calculate_order_book_depth(bids, asks, depth=100):\n",
        "    \"\"\"Calculate total volume at different price levels (e.g., top 100 bids/asks).\"\"\"\n",
        "    try:\n",
        "        bid_volumes = [bid[1] for bid in bids[:depth]]\n",
        "        ask_volumes = [ask[1] for ask in asks[:depth]]\n",
        "        return sum(bid_volumes), sum(ask_volumes)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error calculating order book depth: {e}\")\n",
        "        return 0, 0\n",
        "\n",
        "# Identify High-Quality Liquidity Zones\n",
        "def identify_liquidity_zones(bids, asks, volume_threshold=100, price_tolerance=0.001):\n",
        "    \"\"\"\n",
        "    Identify high-quality liquidity zones (areas with significantly higher liquidity).\n",
        "\n",
        "    Parameters:\n",
        "        bids (list): List of bid prices and volumes.\n",
        "        asks (list): List of ask prices and volumes.\n",
        "        volume_threshold (float): Minimum volume to consider a zone significant.\n",
        "        price_tolerance (float): Maximum price difference to group into a single zone.\n",
        "\n",
        "    Returns:\n",
        "        bid_zones (list): List of significant bid liquidity zones.\n",
        "        ask_zones (list): List of significant ask liquidity zones.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract prices and volumes\n",
        "        bid_prices = [bid[0] for bid in bids]\n",
        "        bid_volumes = [bid[1] for bid in bids]\n",
        "        ask_prices = [ask[0] for ask in asks]\n",
        "        ask_volumes = [ask[1] for ask in asks]\n",
        "\n",
        "        # Function to group prices into zones\n",
        "        def group_prices(prices, volumes, tolerance):\n",
        "            zones = []\n",
        "            current_zone = []\n",
        "            current_price = None\n",
        "\n",
        "            for price, volume in zip(prices, volumes):\n",
        "                if current_price is None or abs(price - current_price) <= tolerance:\n",
        "                    current_zone.append((price, volume))\n",
        "                    current_price = price\n",
        "                else:\n",
        "                    zones.append(current_zone)\n",
        "                    current_zone = [(price, volume)]\n",
        "                    current_price = price\n",
        "\n",
        "            if current_zone:\n",
        "                zones.append(current_zone)\n",
        "            return zones\n",
        "\n",
        "        # Group bid and ask prices into zones\n",
        "        bid_zones = group_prices(bid_prices, bid_volumes, price_tolerance)\n",
        "        ask_zones = group_prices(ask_prices, ask_volumes, price_tolerance)\n",
        "\n",
        "        # Filter zones based on volume threshold\n",
        "        def filter_zones(zones, threshold):\n",
        "            filtered = []\n",
        "            for zone in zones:\n",
        "                total_volume = sum(vol for _, vol in zone)\n",
        "                if total_volume >= threshold:\n",
        "                    avg_price = sum(price * vol for price, vol in zone) / total_volume\n",
        "                    filtered.append((avg_price, total_volume))\n",
        "            return filtered\n",
        "\n",
        "        bid_liquidity_zones = filter_zones(bid_zones, volume_threshold)\n",
        "        ask_liquidity_zones = filter_zones(ask_zones, volume_threshold)\n",
        "\n",
        "        return bid_liquidity_zones, ask_liquidity_zones\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error identifying liquidity zones: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Preprocess Order Book Data\n",
        "def preprocess_order_book(bids, asks):\n",
        "    \"\"\"Extract features from Level 2 order book.\"\"\"\n",
        "    try:\n",
        "        if not bids or not asks:\n",
        "            return [0, 0, 0, 0]\n",
        "\n",
        "        bid_prices = np.array([bid[0] for bid in bids])\n",
        "        bid_sizes = np.array([bid[1] for bid in bids])\n",
        "        ask_prices = np.array([ask[0] for ask in asks])\n",
        "        ask_sizes = np.array([ask[1] for ask in asks])\n",
        "\n",
        "        spread = ask_prices[0] - bid_prices[0]\n",
        "        vwap = np.sum(bid_prices * bid_sizes) / np.sum(bid_sizes)\n",
        "        imbalance = np.sum(bid_sizes) - np.sum(ask_sizes)\n",
        "        bid_ask_ratio = np.sum(bid_sizes) / np.sum(ask_sizes)\n",
        "\n",
        "        return [spread, vwap, imbalance, bid_ask_ratio]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error preprocessing order book: {e}\")\n",
        "        return [0, 0, 0, 0]\n",
        "\n",
        "# Time-Based Features\n",
        "def get_time_features():\n",
        "    \"\"\"Get time-based features: Hour of day & Day of week.\"\"\"\n",
        "    try:\n",
        "        now = datetime.datetime.utcnow()\n",
        "        hour_of_day = now.hour / 24  # Normalize (0-1)\n",
        "        day_of_week = now.weekday() / 6  # Normalize (0-1)\n",
        "        return [hour_of_day, day_of_week]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error getting time features: {e}\")\n",
        "        return [0, 0]\n",
        "\n",
        "# Load & Scale Data for LSTM\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# LSTM Model Definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 7)),  # Updated to 7 features\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# List of Assets to Analyze\n",
        "assets = ['AVAX/USDT', 'CRV/USDT', 'NEAR/USDT', 'LINK/USDT', 'JUP/USDT']\n",
        "\n",
        "for asset in assets:\n",
        "    try:\n",
        "        # Fetch Order Book & Trade Data\n",
        "        bids, asks = fetch_order_book(asset, depth=100)  # Use depth=100\n",
        "        trade_data = fetch_trade_data(asset)\n",
        "\n",
        "        if trade_data.empty:\n",
        "            logging.warning(f\"No trade data found for {asset}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Classify Aggressive Orders\n",
        "        trade_data = classify_aggressive_orders(trade_data, bids, asks)\n",
        "\n",
        "        # Calculate Trade Volumes and Aggressive Orders\n",
        "        aggressive_orders_4h = analyze_aggressive_orders(trade_data, '4h')  # Use 'h' instead of 'H'\n",
        "        aggressive_orders_15m = analyze_aggressive_orders(trade_data, '15min')  # Use 'min' instead of 'T'\n",
        "\n",
        "        # Calculate Order Book Depth (Top 100 Bids/Asks)\n",
        "        bid_depth, ask_depth = calculate_order_book_depth(bids, asks, depth=100)\n",
        "\n",
        "        # Identify High-Quality Liquidity Zones\n",
        "        bid_liquidity_zones, ask_liquidity_zones = identify_liquidity_zones(\n",
        "            bids, asks, volume_threshold=100, price_tolerance=0.001\n",
        "        )\n",
        "\n",
        "        # Combine Features for LSTM\n",
        "        new_features = preprocess_order_book(bids, asks) + [\n",
        "            aggressive_orders_4h['delta'].iloc[-1] if not aggressive_orders_4h.empty else 0,\n",
        "            aggressive_orders_15m['delta'].iloc[-1] if not aggressive_orders_15m.empty else 0\n",
        "        ] + get_time_features()\n",
        "\n",
        "        # Ensure Exactly 7 Features for LSTM\n",
        "        new_features = new_features[:7]\n",
        "\n",
        "        # Scale the Features\n",
        "        scaled_features = scaler.fit_transform([new_features])\n",
        "\n",
        "        # Reshape to match LSTM input (1 sample, 1 time step, 7 features)\n",
        "        X_new = np.array(scaled_features).reshape(1, 1, 7)\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(X_new)[0][0]\n",
        "\n",
        "        # Generate Trading Signal\n",
        "        if prediction > 0.2:\n",
        "            signal = \"ðŸš€ BUY Signal\"\n",
        "        elif prediction < -0.2:\n",
        "            signal = \"ðŸ”» SELL Signal\"\n",
        "        else:\n",
        "            signal = \"âŒ NO TRADE\"\n",
        "\n",
        "        # Output Results\n",
        "        print(f\"\\nðŸ”¹ {asset}\")\n",
        "        print(f\"ðŸ“ˆ Prediction: {prediction:.4f}\")\n",
        "        print(f\"ðŸ“Š Trading Signal: {signal}\")\n",
        "        print(f\"ðŸ“Š 4H Aggressive Buying/Selling: {aggressive_orders_4h['delta'].iloc[-1]:.2f}\")\n",
        "        print(f\"ðŸ“Š 15M Aggressive Buying/Selling: {aggressive_orders_15m['delta'].iloc[-1]:.2f}\")\n",
        "        print(f\"ðŸ“Š Order Book Depth (Top 100 Bids/Asks): {bid_depth:.2f} / {ask_depth:.2f}\")\n",
        "        print(f\"ðŸ“Š Bid Liquidity Zones: {[f'{price:.4f} ({vol:.2f})' for price, vol in bid_liquidity_zones]}\")\n",
        "        print(f\"ðŸ“Š Ask Liquidity Zones: {[f'{price:.4f} ({vol:.2f})' for price, vol in ask_liquidity_zones]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"\\nðŸ”¹ {asset}\")\n",
        "        logging.error(f\"âš ï¸ Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT3uuraUVEzQ",
        "outputId": "2114c90e-87cb-4b2c-be49-fb176ada57e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "\n",
            "ðŸ”¹ AVAX/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 12654.39\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 12624.66\n",
            "ðŸ“Š Order Book Depth (Top 100 Bids/Asks): 8028.36 / 6299.11\n",
            "ðŸ“Š Bid Liquidity Zones: ['24.4350 (239.95)', '24.4317 (114.02)', '24.4288 (160.47)', '24.4112 (634.57)', '24.4100 (348.35)', '24.4010 (103.25)', '24.3994 (872.25)', '24.3950 (125.94)', '24.3901 (399.46)', '24.3870 (119.72)', '24.3799 (338.71)', '24.3730 (345.77)', '24.3580 (137.44)', '24.3540 (431.79)', '24.3380 (423.51)', '24.3370 (1128.24)', '24.3000 (117.89)', '24.2830 (191.29)']\n",
            "ðŸ“Š Ask Liquidity Zones: ['24.4800 (148.26)', '24.4866 (427.92)', '24.4920 (450.96)', '24.4980 (120.36)', '24.5000 (344.09)', '24.5100 (625.99)', '24.5260 (132.34)', '24.5370 (346.68)', '24.5501 (511.27)', '24.5600 (1158.62)', '24.5920 (114.10)', '24.6430 (110.74)']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "ðŸ”¹ CRV/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: -700.07\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: -434.17\n",
            "ðŸ“Š Order Book Depth (Top 100 Bids/Asks): 366733.88 / 139012.89\n",
            "ðŸ“Š Bid Liquidity Zones: ['0.5053 (263586.41)', '0.4923 (103147.47)']\n",
            "ðŸ“Š Ask Liquidity Zones: ['0.5113 (139012.89)']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "ðŸ”¹ NEAR/USDT\n",
            "ðŸ“ˆ Prediction: 0.0000\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: 10412.83\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: 1043.14\n",
            "ðŸ“Š Order Book Depth (Top 100 Bids/Asks): 52957.69 / 54058.75\n",
            "ðŸ“Š Bid Liquidity Zones: ['3.2277 (44108.72)', '3.2159 (3571.14)', '3.2131 (2513.93)', '3.2107 (155.73)', '3.2068 (2604.16)']\n",
            "ðŸ“Š Ask Liquidity Zones: ['3.2491 (53885.44)', '3.2623 (173.30)']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ LINK/USDT\n",
            "ðŸ“ˆ Prediction: nan\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: nan\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: nan\n",
            "ðŸ“Š Order Book Depth (Top 100 Bids/Asks): 5944.16 / 13448.10\n",
            "ðŸ“Š Bid Liquidity Zones: ['18.2293 (451.58)', '18.2239 (367.11)', '18.2223 (217.22)', '18.2190 (374.30)', '18.2148 (1333.22)', '18.2097 (1150.47)', '18.2074 (152.79)', '18.2020 (797.59)', '18.1971 (489.23)', '18.1943 (347.78)', '18.1864 (116.72)']\n",
            "ðŸ“Š Ask Liquidity Zones: ['18.2440 (111.46)', '18.2464 (435.94)', '18.2502 (367.41)', '18.2559 (460.89)', '18.2589 (332.18)', '18.2631 (110.13)', '18.2699 (1450.28)', '18.2726 (1314.88)', '18.2756 (156.43)', '18.2771 (558.54)', '18.2837 (152.77)', '18.2858 (178.88)', '18.2880 (1133.36)', '18.2916 (162.97)', '18.2967 (509.34)', '18.3003 (351.95)', '18.3064 (1639.07)', '18.3132 (1070.82)', '18.3159 (178.88)', '18.3292 (553.22)', '18.3336 (653.55)', '18.3383 (962.62)', '18.3455 (162.63)']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "ðŸ”¹ JUP/USDT\n",
            "ðŸ“ˆ Prediction: nan\n",
            "ðŸ“Š Trading Signal: âŒ NO TRADE\n",
            "ðŸ“Š 4H Aggressive Buying/Selling: nan\n",
            "ðŸ“Š 15M Aggressive Buying/Selling: nan\n",
            "ðŸ“Š Order Book Depth (Top 100 Bids/Asks): 244602.62 / 185412.86\n",
            "ðŸ“Š Bid Liquidity Zones: ['0.8240 (244602.62)']\n",
            "ðŸ“Š Ask Liquidity Zones: ['0.8319 (184312.18)', '0.8472 (1100.69)']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        }
      ]
    }
  ]
}